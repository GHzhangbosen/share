1、HashMap底层存储结构；当发生Hash冲突时，怎么处理？
通过链表的形式处理hash冲突
2、接第一题：在JDK1.8中，对HashMap做了什么优化？
a.为了解决链表过长导致查询过慢的问题，1.8引入了红黑树，提升查询效率
b.hash操作减少了扰动函数的调用次数，1.8仅仅做了两次扰动，一次位运算 + 一次异或运算
c.改为尾插法进行数据添加，这样就避免了多线程引起的环状链表问题
3、拉链法导致的链表深度过深的问题，为什么不用二叉查找树，而是使用红黑树来解决？
  1.我的理解是红黑树可以有自己自平衡策略，虽然查找树查询也很快，但是没有自平衡，容易造成树变链表
4、说说你对红黑树的理解，有啥特点？
  1.每个节点的颜色非黑即白，根结点一定是黑色，叶子结点一定是黑色
  2.父子结点必须不同颜色
  3.从一个结点到这个结点的子孙结点的所有路径上，包含相同数量的黑色结点
  4.没有一条路径会比其他路径长2倍，接近平衡二叉树
  5.时间复杂度是logn
5、ConcurrentHashMap线程安全吗？怎么做到的？以及在JDK1.7、1.8版本的区别（主要针对锁粒度，做了什么优化处理？）
  1.7：底层采用segment和hashentrie数据结构，锁的对象是segment
  1.8：cas操作在修改上
6、在线程安全方面，为什么说ConcurrentHashMap比HashTable效率要高？
  1.后者锁的是整个hash数组，而前者采用锁分离技术锁的是各个segment，segment维护着不同段落的hashmap，所以在进行修改操作时，不同segment可以并发执行
  2.前者有些操作需要跨段，size contains等，这时候要进行顺序锁定所有段，操作完毕后，再顺序释放所有锁
7、HashMap使用数组进行存储，当需要扩容时，它的扩容过程是？
  1.7:首先保存旧数组数据，然后2倍创建新的数组，将旧数组的数据遍历，然后do while循环拿到链表数据，正序遍历并且重新计算index，头插法插入到新数组中。计算好新的扩容阈值
  1.8:首先保存旧数组数据，然后2倍创建新的数组，将旧数组的数据遍历，然后do while循环拿到链表数据，正序遍历并且重新计算index(和1.7有区别，下面有)，尾插法插入到新数组中。计算好新的扩容阈值
8、AsyncTask了解吗？它的工作原理，以及存储结构是啥？
  AsyncTask是来做子线程任务执行，内部有线程池以及handler进行线程通信，而内部线程池其实接到的任务也是做串行执行的。
9.为什么hashmap的数组长度会被强制设置为2的整数次幂
  1.正常来讲，我们取hash(key)后，会对数据的长度进行取余操作，然后拿到对应的index，但是对于计算机来讲，取余操作在基数为2的整数次幂下，hash(key) % length和 hash(key) & length - 1
  两者的结果是一样的，而后者效率更高，位操作效率高。所以这里采用了后者进行索引确定
  2.同时，2的整数次幂为高位是1，低位都是0，减去1之后，高位是0，低位都是1.这时hash(key) & length - 1，结果可能为1(奇数)，可能为0(偶数)，而如果不减一，那么2的整数次幂一定是偶数，也就是低位是0
  这时候再&，结果最后一位一定是0，一定是偶数，这样的情况，出来的index一定都是偶数，空间就直接缩了一半。
10.1.8版本做hash函数时，(h = key.hashCode()) ^ (h >>> 16) 做的hash，为什么？
  1.一般整数的hashcode都很大，这时高位有0 1 等，而length一般都很小，尤其在客户端，比如length是16， -1后高位是0，低位是1111，这时候 & length - 1 ，hashcode的高位对结果是没有影响的，
  所以这里做了hashcode的低16位异或了它的高16位，这样，高低位的结果对整体的结果都有了影响，减少了碰撞率。为什么不用|或者&  原因是异或操作的两个参数对结果都有影响。
11.1.8版本扩容的index计算方式
  1.扩容后，如果hash值的新增参与运算的位=0，那么元素在扩容后的位置 = 原始位置
  2.扩容后，如果hash值的新增参与运算的位=1，那么元素在扩容后的位置 = 原始位置 + 扩容前的旧容量
  原因：因为是&操作，所以扩容2倍后，length - 1，会高位增加一位，所以hash后的值也要多一个位出来参与运算


  ====================================================================================================================================================================================

  1、内存优化做过什么工作？
    1.在开发过程中对内存泄露自测，使用leakcanary
    2.可以通过android profile来查看指定时间段的内存情况
    3.要重点注意内存泄露，比如handler，static，map，广播，服务，数据库使用后要进行资源释放
    bitmap使用时注意压缩裁剪，

  2、用过Glide吗？如果让你去设计，你会怎么做？应该考虑哪几个方面？
    用过。
    1.图片数据的缓存（不同转换格式的缓存key，内存缓存  硬盘缓存）
    2.图片数据的压缩，裁剪
    3.图片数据的获取(网络，本地)
    4.生命周期的设置回调（成功，失败，错误等等）
    
    这个答案我不确定好不好，你重点看一下
    ==============
    https://mp.weixin.qq.com/s/J7Q263kqSdeyh1tvunKLsA

  3、在一个大型项目中，如果线上Crash，如何快速定位到具体的责任人？
    1.大型项目开发采用组件化，各个组件单独维护
    2.组件内也采用低耦合进行开发，也就是各个小模块之间尽量采用路由形式调用，降低耦合。
    3.根据每一个类上的注释信息(RD开发中创建的类)
    4.如果是修改别人的类，强制要求RD在修改的方法或者类上加上对应的注释，表明修改时间和原因
    

  4、自定义View的过程了解吗？
    重点在onmeasure onlayout ondraw
    onmeasure 
      viewgroup：递归调用子viewgroup，一直到子view的onmeasure
      view：调用measure
    参数：measurespec：高两位是mode 低30位是size
       mode：是父控件的测量规格
       size：父控件剩余的大小
       父mode= exactly 
         子：wrap  结果 子mode = atmost
         子：match  结果 子mode = exactly
         子：具体   结果  子mode = exactly
       父mode= atmost
         子：wrap  结果 子mode = atmost
         子：match  结果 子mode = atmost
         子：具体  结果 子mode = 
         子：wrap  结果 子mode = exactly
       父mode= 无限制
         子：wrap  结果 子mode = 无限制
         子：wrap  结果 子mode = 无限制
         子：具体   结果子mode = exactly
         
    onlayout：上下左右
    ondraw：绘制

  5、平时工作过程中，让你印象最深刻的问题是什么？怎么解决的？


  6、对象加锁的原理了解吗？乐观锁、悲观锁是啥？sychronized、volatile的区别。还了解其他锁吗？
    乐观锁和悲观锁对于RD来讲，我觉得是从开发层面来说，当分析到当前的业务代码是暴露在多线程下，主观认为是不安全的，那么就是悲观锁，反之，乐观锁
    概念：对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候回先加锁，确保数据不会被别的线程修改。
    java中，sychronized和lock的实现类都是悲观锁
        乐观锁认为自己在使用数据的时候不会有别的线程对数据进行修改，所以不会上锁，只是在更新数据的时候查看一下当前数据是不是以前的数据，如果数据没有被
        更新，那么直接写入数据，反之，根据不同的实现方式执行不同的操作（例如报错或者自动重试）
    轻量级，重量级，偏向锁，无锁态，可重入锁，非可重入，公平，非公平，独享锁，共享锁

  7、TCP建立连接几次握手？断开连接几次握手？为什么？
    3 4
    握手：
      1.三次握手保证了cs两端序列号的确认
      2.三次握手保证了消息发送有序 可靠
      3.三次握手保证了历史消息遗留问题
      4.三次握手减少了资源的浪费，如果两次握手，客户端发送syn信号给服务端，服务端直接建立连接发回ack，这时候网络延迟，客户端接收不到ack，所以重新发送syn，那么服务端就多次建立连接
    挥手：
      1.四次挥手保证cs两端都能安全关闭连接(所谓安全，就是没有没发送的数据)
      2.第四次握手确保了客户端关闭了连接

      ===============
      复议：四次挥手，是因为TCP链接采用全双工工作模式
      

  8、HTTP连接请求的过程。报文格式了解吗？
    1.客户端发送域名网络情况
    2.本地dns解析域名，返回对应ip
    3.根据ip查找对应服务器，根据host定位到真正的服务器
    4.发送http请求报文，
    5.服务器处理逻辑返回
    
    报文格式
      请求报文：
        请求行 方法：path：协议版本
        请求头 contenttype contentlength useragent range cookie等
        
        body
      返回报文
        响应行 协议版本：code：message
        响应头 contenttype setcookie 等
        
        body
        

  9、HTTPS的连接建立过程
    1.clienthello 客户端随机数和安全套件发到server 
    2.serverhello 服务端随机数和选择的安全组件的具体(tls版本 cipher suite(对称加密算法，非对称加密算法，hash算法))发到client
    3.server发出对应的证书(公钥 签名 二级签名机构的公钥证书等) 
          a) client首先验证服务端证书中的Host是否是自己请求的域名
					b) 如果验证通过。那么client会继续验证，服务端公钥签名 是否能被服务端证书中的二级签发机构的公钥验证
					c) 如果验证通过，说明这个证书确实是被二级签发机构私钥的持有者签发的。那么需要继续验证二级机构签发方的信息，是否在系统根证书中
					d) 如果在，就说明该证书可信，是自己请求服务器的证书
    4.pre-master-secret(随机数)，使用非对称加密传输到服务端
      服务端接收到pre master secret后
      客户端和服务端使用相同的算法，根据客户端随机数，服务端随机数和pre master secret 分别生成master secret
      客户端使用master secret以及算法，生成客户端加密密钥，服务端加密密钥，客户端mac secret(随机数，对原消息加盐的)
      服务端使用master secret以及算法，生成服务端加密密钥，客户端加密密钥，服务端mac secret
      为什么生成两个对称密钥，原因是防止有中间人中间拦截消息，原封不动返回
      
      hmac函数就是改良的hash，作用是来验证消息是否被篡改
      客户端发送密文以及明文的摘要，服务端接收，密钥解密拿到明文，再用hmac对明文进行摘要，和客户端发过来的对比，相同证明没有被篡改
    5.客户端说”我要使用加密通信了“(特定字节)
    6.客户端发送”finished“，包含上面所有的信息，服务端接收后，如果能解密看懂
    7.服务端发送”我要使用加密通信了“（特定字节）
    8.服务端发送”finished“ 包含上面所有信息，客户端能看懂，代表双方可以使用https通信了
   
      
  
  10.自适应自旋锁
    意味着自选的时间(次数)不再固定，而是由前一次在同一个锁上的自选时间以及所的拥有者的状态所决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在进行中，
    那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，
    直接挂起，避免浪费处理器资源
    ==========
复议：sychronized、volatile都是自旋锁

  11.无锁
    无锁就是没有对资源进行锁定，所有的线程都能访问并且修改同一个资源，但是同时只有一个线程可以修改成功 
    无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改，如果没有冲突就修改成功并且退出，否则就会继续循环尝试，如果有多个线程修改同一个值，必定会有一个线程能修改成功，其他线程
    就会不断的循环尝试修改成功，就是CAS
  12.偏向锁
    偏向锁是指同一个资源一直被同一个线程访问，不存在锁竞争的情况，这样线程会自动获取锁，降低获取锁的代价
    目的就是在只有一个线程执行同步代码块时能够提供性能
    当一个线程访问同步代码块并且获取锁时，会在MARK WORD里存储锁偏向的线程id，在线程进入和退出同步快时不需要再通过cas操作来加锁和解锁，而是检测mark word里是否存储着指向当前线程的
    偏向锁，就是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取和释放都要多次cas，浪费处理器资源，而偏向锁只需要在第一次置换threadid时依赖一次cas操作
    
    偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁，偏向锁的撤销，需要等全局安全点(在这个时间点上没有字节码正在执行)，它会首先暂停有用偏向锁的线程，
    判断锁对象是否被锁定，然后撤销偏向锁变为无锁状态。

=============
    复议：偏向锁：当A线程首次访问资源后，CPU并不会马上释放锁。而是等待资源第二次被访问。如果第二次访问资源的线程还是A，那么就不用重复加锁了；如果不是线程A，那么就要先经历线程A释放锁，然后线程B加锁
    
  13.轻量级锁
    指当锁为偏向锁时，被其他线程竞争，就升级为轻量级锁，其他线程也是通过cas，也就是循环来尝试获取锁，不会阻塞，相对提升性能
    在代码进行同步块时，如果是无锁状态，虚拟机首先将在当前线程的栈帧中创建一个名为锁记录的空间(lock record)，用来存储锁对象目前的mark word的副本，然后拷贝对象头中的mard word复制到锁记录中
    拷贝成功后，虚拟机将使用cas操作尝试将对象的mark word更新为指向lock record的指针，并且将lock record里的owner指针指向对象的mark word

=============
    复议：轻量级锁在进行CAS重试机制时，会设置一个上限阈值。超过阈值后，轻量级锁会膨胀为重量级锁
    
  14.重量级锁
  交给操作系统进行调度，线程都进入队列进入阻塞状态
  总结：偏向锁通过对比mark word解决加锁问题，避免了不必要的cas操作，轻量级锁通过cas来解决线程状态的切换的资源浪费，重量级锁直接将没有锁的线程阻塞
    
    

  ====================================================================================================================================================================================
  1、Binder机制了解吗？能说下进程通信的过程吗？
  binder机制是android系统下的ipc进程间通信方式，说到binder就要把内存分为内核态和用户态，内核态对于用户态来讲都是共享的，可以通过系统提供的api进行访问，binder
  是cs模型，当s端在system_server注册自己的binder时，内核态就将s端的binder驱动存入对应的注册表中，也在内核态的共享内存做了mmap映射，这样，c端通过system_server
  获取s端binder代理对象，进而可以进行远程调用


  2、Serializable和Parcelable的区别
  1.Serializable是java里的序列化方式,Parcelable是android特有的序列化方式
  2.serializable使用起来相对parcelable简单，只要实现类，定义描述关键字即可
  3.parcelable需要去实现序列化和反序列化的过程
  4.serializable常用于数据的保存，parcelable常用在内存数据的传输，也能保存，需要转为二进制，再进行文件保存

  3、Handler通信过程
  1.创建handler后，对应的looper创建，messagequeue消息队列创建
  2.开启loop轮询消息，进行死循环轮询，无消息，无阻塞，而是休眠状态，linux下的epoll/pipe管道机制，监听多个描述符的
  3.hander通过threadlocal进行线程绑定以及线程切换
  4.手动创建looper后，不需要时要进行quit操作，结束消息轮询
  5.内存泄露问题通过static和weakreference解决
  

  4、垃圾回收算法
  1.标记清除 会有内存碎片问题
  2.标记整理清除 内存碎片解决，但是整理内存时需要移动内存位置，这样会有性能问题
  3.复制清除  会有一半内存未使用

  5、Android启动过程
  1.activity.startactivity传入当前的intent extra等信息
  2.startactivityforresult 调用instrumentation.execstartactivity，这里直接调用了activitymanagerproxy.startactivity
  3.开始跨进程通信，调用到ams.startactivity.转入activitystack.startactivity
  4.判断标志位，判断当前resume的activity，判断pauseactivity等等变量，再次跨进程
  5.将当前的activity置为pause状态，再跨进程
  6.变量赋值，判断当前taskrecored，判断启动模式，判断意图等，进行变量赋值，再跨进程
  7.开始反射创建applicaiton，创建activity

  6、线程安全的起因
  由于jvm对内存划分有共享的内存和线程私有的内存，堆和栈，当多个线程操作同一份内存对应的变量时，就会产生线程安全问题

  7、了解哪些设计模式
  常用的有 单例，适配器，外观，模板，代理，装饰，桥接，策略等

  8、类加载机制
  加载-链接-初始化
  加载-验证-准备-解析-初始化-使用-卸载
  加载
    负责将字节码文件加载到内存中，这个内存空间就是方法区
    1.通过类的全限定名称获取定义此类的二进制字节流，本地，网络
    2.将字节流所对的静态存储结构转化为方法区中运行时的数据结构
    3.在内存中生成累的java lang class对象，就是方法区中对外暴露的数据访问入口
  偶尔加载和连接(比如字节码格式的验证)的执行是交叉执行的，但是两个阶段的开始时间是按照固定顺序，还有，jvm加载数组的时候
  是加载数组内的数据类型，比如string【】，加载器仅仅会加载string，因为数组是相同类型，减少不必要的加载次数，多维数组就
  递归，从外到内加载。
  
  验证
    验证是连接阶段的第一步，为了保确保class文件的字节流中包含的信息符合当前虚拟机的要求
    1.文件格式的验证：验证字节流是否符合class文件格式的规范
    2.元数据验证：对字节码描述的信息进行语义分析，保证java规范
    3.字节码验证：通过数据流和控制流分析，确保程序语义的合法性和逻辑性
    4.符号引用验证：确保解析动作能正确执行
  验证阶段重要但不是必须的，当所应用的类已经经过反复验证，我们可以采用-xverifynone参数关闭大部分验证
  
  准备
    准备阶段就是给静态属性变量赋值，这些变量都会在方法区中，所以变量都是被static修饰的变量，而实例变量是随着对象的实例化在堆内存分配的
    入static int test = 333；准备阶段赋值是0，在执行java方法时，才会赋值333
    
  解析
    解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。解析动作主要针对类或接口，字段，类方法，接口方法，方法类型，方法句柄和调用点限定符7类符号引用进行
    
  初始化
    初始化阶段真正执行类中定义的java程序代码
1.遇到new、getstatic、putstatic或者invokestatic这四条字节码指令时，如果没有进行过初始化，则先出发初始化。生成这四条指令的常见场景：使用new关键字实例化对象，读取或者设置一个类的静态字段(被final修饰，已经在编译期就赋值放入到常量池的静态字段除外)，还有调用一个类的静态方法。 

2.使用java.lang.reflect包的方法对类进行反射调用的时候，如果没有初始化，则初始化。 

3.初始化一个类的时候，如果父类没初始化      

4.虚拟机启动时，需要指定程序入口，也就是main方法，那么main方法所在的类需要主动初始化。

只有以上四种为主动引用，其他都是被动引用了
    

  9、讲述内存模型
  java虚拟机栈，本地方法栈，方法区，程序计数器，堆

