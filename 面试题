1、HashMap底层存储结构；当发生Hash冲突时，怎么处理？
通过链表的形式处理hash冲突
2、接第一题：在JDK1.8中，对HashMap做了什么优化？
a.为了解决链表过长导致查询过慢的问题，1.8引入了红黑树，提升查询效率
b.hash操作减少了扰动函数的调用次数，1.8仅仅做了两次扰动，一次位运算 + 一次异或运算
c.改为尾插法进行数据添加，这样就避免了多线程引起的环状链表问题
3、拉链法导致的链表深度过深的问题，为什么不用二叉查找树，而是使用红黑树来解决？
  1.我的理解是红黑树可以有自己自平衡策略，虽然查找树查询也很快，但是没有自平衡，容易造成树变链表
4、说说你对红黑树的理解，有啥特点？
  1.每个节点的颜色非黑即白，根结点一定是黑色，叶子结点一定是黑色
  2.父子结点必须不同颜色
  3.从一个结点到这个结点的子孙结点的所有路径上，包含相同数量的黑色结点
  4.没有一条路径会比其他路径长2倍，接近平衡二叉树
  5.时间复杂度是logn
5、ConcurrentHashMap线程安全吗？怎么做到的？以及在JDK1.7、1.8版本的区别（主要针对锁粒度，做了什么优化处理？）
  1.7：底层采用segment和hashentrie数据结构，锁的对象是segment
  1.8：cas操作在修改上
6、在线程安全方面，为什么说ConcurrentHashMap比HashTable效率要高？
  1.后者锁的是整个hash数组，而前者采用锁分离技术锁的是各个segment，segment维护着不同段落的hashmap，所以在进行修改操作时，不同segment可以并发执行
  2.前者有些操作需要跨段，size contains等，这时候要进行顺序锁定所有段，操作完毕后，再顺序释放所有锁
7、HashMap使用数组进行存储，当需要扩容时，它的扩容过程是？
  1.7:首先保存旧数组数据，然后2倍创建新的数组，将旧数组的数据遍历，然后do while循环拿到链表数据，正序遍历并且重新计算index，头插法插入到新数组中。计算好新的扩容阈值
  1.8:首先保存旧数组数据，然后2倍创建新的数组，将旧数组的数据遍历，然后do while循环拿到链表数据，正序遍历并且重新计算index(和1.7有区别，下面有)，尾插法插入到新数组中。计算好新的扩容阈值
8、AsyncTask了解吗？它的工作原理，以及存储结构是啥？
  AsyncTask是来做子线程任务执行，内部有线程池以及handler进行线程通信，而内部线程池其实接到的任务也是做串行执行的。
9.为什么hashmap的数组长度会被强制设置为2的整数次幂
  1.正常来讲，我们取hash(key)后，会对数据的长度进行取余操作，然后拿到对应的index，但是对于计算机来讲，取余操作在基数为2的整数次幂下，hash(key) % length和 hash(key) & length - 1
  两者的结果是一样的，而后者效率更高，位操作效率高。所以这里采用了后者进行索引确定
  2.同时，2的整数次幂为高位是1，低位都是0，减去1之后，高位是0，低位都是1.这时hash(key) & length - 1，结果可能为1(奇数)，可能为0(偶数)，而如果不减一，那么2的整数次幂一定是偶数，也就是低位是0
  这时候再&，结果最后一位一定是0，一定是偶数，这样的情况，出来的index一定都是偶数，空间就直接缩了一半。
10.1.8版本做hash函数时，(h = key.hashCode()) ^ (h >>> 16) 做的hash，为什么？
  1.一般整数的hashcode都很大，这时高位有0 1 等，而length一般都很小，尤其在客户端，比如length是16， -1后高位是0，低位是1111，这时候 & length - 1 ，hashcode的高位对结果是没有影响的，
  所以这里做了hashcode的低16位异或了它的高16位，这样，高低位的结果对整体的结果都有了影响，减少了碰撞率。为什么不用|或者&  原因是异或操作的两个参数对结果都有影响。
11.1.8版本扩容的index计算方式
  1.扩容后，如果hash值的新增参与运算的位=0，那么元素在扩容后的位置 = 原始位置
  2.扩容后，如果hash值的新增参与运算的位=1，那么元素在扩容后的位置 = 原始位置 + 扩容前的旧容量
  原因：因为是&操作，所以扩容2倍后，length - 1，会高位增加一位，所以hash后的值也要多一个位出来参与运算
